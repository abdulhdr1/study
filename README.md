This is a mixture of learn in public with note taking project that aims on better organizing my links/references and topics I'm interested in/following on.
You can find the topics and their related notes as [issues](https://github.com/abdulhdr1/study/issues), the basic issue structure is a title categorizing the topic in as few words as possible, some are going to be really broad like [life advice](https://github.com/abdulhdr1/study/issues/8) and others will be focused on a single thing, like a [course](https://github.com/abdulhdr1/study/issues/7) or an [issue](https://github.com/abdulhdr1/study/issues/3) I'm working on. the issue body will usually be just a bunch of links where i can learn more about the topic, and as i go through them i add comment on the issue linking to what i've seen and a small note on the contents. 

Why:
i like the append only nature of github issues, you can follow the progress as a topic gets discussed. also, this not-very-structured approach means i don't really need to bother summarizing everything i've read/learned about something, i can simply choose something to read and after that write a few lines about it.  

Current problems:
- where do I keep a list of references? 
    I'm currently only referencing specific blog posts/essays, but I'd like to have a single list of "interesting blogs" that I could check every one in a while to keep up if with what they've written
- i have too many things to see.
    yes. i'm aware, but i also believe that skimming is one of the most important skills you can have in a content flooded world. that aside, how can i filter out whats not relevant? (maybe a plan on focusing on just a single topic for an X amount of time or learning to deal with not ever knowing everything)
    should the filtering be higher on the funnel?
- how do i a define to topic for a given link?
- what about super specific links, where do they go? examples:
    - https://thenetworkstate.com/
    - https://www.baeldung.com/cs/hashing-separate-chaining
    - https://openai.com/blog/our-approach-to-alignment-research